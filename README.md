# 语言模型的复读问题
## 背景
复读问题（Repetition）是自然语言处理领域研究已久的问题。较小的模型在解决普通任务时常常发生明显的复读（单词或短句级别的重复），而大模型在处理类似枚举的任务或复杂推理任务时也会发生一定程度的循环重复尝试（重复的循环节会更长，或者是语义上的重复）。一定程度上，这也阻碍了模型通过增加推理长度来提升能力。
 
## 任务
在本次作业中，请你在查找研读相关文献之后，对复读问题展开一定的探索研究，（1）探索减轻复读的方法，（2）开展评测，（3）并对复读的成因进行分析。你可以根据自己的计算资源和研究需要，使用任意开源/闭源模型和数据集（下面的例子中提供了一些数据集和模型可供参考，但也欢迎你使用其他实验设置）。

### 减轻复读
1. 你可以沿着既有的尝试，在模型解码时设计合理的规则改善复读（近期的一篇工作是Rethinking Repetition Problems of LLMs in Code Generation https://arxiv.org/pdf/2505.10402，你可以参考它的设置）。
2. 你也可以通过微调或精心设计的上下文工程来改善这一点。
3. 
需要注意的是，在改善复读的同时，你需要给出合理的测试来证明模型的性能未受影响（perplexity / benchmark）。

### 评测
1. 你可以研究不同大小/不同架构/不同训练阶段的模型下复读现象的差异，给出证据充分的可靠结论。
2. 也欢迎你尝试收集、构造大模型（指gpt4-o以上级别的闭源模型或deepseek v3以上量级的开源模型）的复读例子，乃至构建评测。注意这些例子尽量贴合现实使用，例如，“让模型重复一句话一千次”是一个几乎必然导致复读（超过1000次重复）的场景，但在用户使用中很少出现这样的任务；“让模型进行不重复成语接龙”是一个相对贴近现实的复读场景（模型在此时很可能产生循环的接龙），“让模型尝试解数学题并发现模型循环尝试固定的解法”是具有较高现实意义的场景（你也可以尝试对这种“贴合现实的程度”进行合适的度量，来方便收集数据）。
3. 
### 原理分析
对于原理分析，我们列出了一些参考文献，你可以参考其中的分析技巧乃至实验设置（请注意这不是完备的综述，在你设计新方法时请自行进行更完备的文献检索）。
A Theoretical Analysis of the Repetition Problem in Text Generation https://arxiv.org/pdf/2012.14660
Learning to Break the Loop: Analyzing and Mitigating Repetitions for Neural Text Generation https://arxiv.org/pdf/2206.02369
Repetition In Repetition Out: Towards Understanding Neural Text Degeneration from the Data Perspective https://arxiv.org/abs/2310.10226
Repetition Neurons: How Do Language Models Produce Repetitions? https://arxiv.org/abs/2410.13497
Understanding the Repeat Curse in Large Language Models from a Feature Perspective https://arxiv.org/pdf/2504.14218v1
特别的，如果你需要分析模型的训练数据以及训练过程的checkpoints等，可以使用OLMO等开源模型项目。

## 作业要求
在本次大作业中，你需要对上述三方面进行探索（考虑到一个小组一般为三人，这三个方面应当都有所涉及）。成绩评定将综合考虑不同维度的探索深度和创新性，而非单纯以效果好坏为凭。

### 组队
自由分组，每组3人。

### 作业呈现形式
1. 书面报告：中文，pdf格式。应条理清晰，明白叙述研究的动机、意义和结论，并包括涉及的细分领域的已有工作的简要介绍。小组成员与分工亦应述及。
2. 代码与数据集等附加材料：请提交实验与分析涉及的代码与数据集，以供查验和复现。
3. 现场报告：除书面报告外，仍需进行一次在上课时进行的现场报告。
注：现场报告安排在12月18日和25日的课程上，书面报告及代码在考试周第一周末截止。

### 评分标准
1. 探索任意一种减轻复读的方法并对其效果进行测试。（20pt）
2. 对模型的复读问题开展合理且有意义的评测（你可以选取前文提到的任意方向，亦可以自行开展其他探索，合理即可）。（20pt）
3. 探索模型的复读原因（可以选取特定模型进行分析，也可以给出更广泛的解释）。（20pt）
4. 现场报告的效果。（15pt）
5. 实验报告的可读性与完整性。（15pt）
6. 上述1-3部分中的创新性与探索深度。（10pt+，不设上限）

注：1-3部分的20pt赋分以完整性和合理性为主，6的评分则以创新性和深度为主。考虑到不同小组计算资源的差异和模型与任务选择的不同，我们不将效果作为唯一评判标准。
